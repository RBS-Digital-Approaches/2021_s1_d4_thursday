{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2021_s1_d4_m2f_reprocess_bad_images.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyM1B0O54rD/17LC0QRNyfgA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Kq3q1oHYC-zE"},"source":["# Re-process bad images\n","If you examine the binarized images, you may well find some where the process we used in the last notebook didn't yield the best results: perhaps Otsu's method didn't yield the best binarization, or perhaps the deskewing routine didn't quite do the trick for a particular page. (I noticed that page 86 fared pretty badly, for instance, and there may be others I'm missing.)\n","\n","This notebook offers an interactive way to tweak the binarization and deskewing methods in order to come up with a better result for any given image. When you have a result that looks better, you can save a new binarized file for  preliminary OCR.\n","\n","If, after checking out the images, you don't see any that need fixing, then you can just skip this altogether. If you do see some that need tweaking, I'd recommend only doing one or two to get a feel for the kinds of adjustments you'd make—in the time we have, there's no need to go for perfect results for all of the images.\n","\n","(**Note:** Because this notebook mostly repackages things we've already done, there are very few comments. There are also some differences here that I introduced to solve little snags along the way. I haven't tested this exhaustively, so some things might not work as expected.)"]},{"cell_type":"code","metadata":{"id":"uRgVSO1N5IrI"},"source":["#Code cell #1\n","#Connect to Google Drive\n","from google.colab import drive\n","drive.mount('/gdrive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_TJWWW-iLikQ"},"source":["#Code cell #2\n","!pip install pytesseract\n","import ipywidgets as widgets\n","from ipywidgets import interact, interact_manual, interactive\n","from PIL import Image, ImageDraw\n","import cv2\n","from google.colab.patches import cv2_imshow\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pytesseract"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wrWhCmS9fjJL"},"source":["#Code cell #3\n","#I'm assuming that you'll be working with the page images I provided. If you're\n","#working on the images you produced yourself in the last notebook, just change\n","#the path below to retrieve the images from your rbs_digital_approaches_2021/output/\n","#folder\n","%cp /gdrive/MyDrive/L-100a/page_images.zip /content/page_images.zip\n","%cd /content/\n","!unzip page_images.zip\n","%cd /content/page_images/\n","!unzip penn_pr3732_t7_1730b.zip"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X3fFU2SD7Ore"},"source":["#Code cell #4\n","image_source_directory = '/content/page_images/penn_pr3732_t7_1730b/'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ihZjgWWc5sJf","cellView":"form"},"source":["#@title 1 - Choose Image to Reprocess\n","#@markdown Run this cell to generate a dropdown menu to select an image that needs to be reprocessed{display: 'form'}\n","image_select = widgets.Dropdown(\n","    description='Choose image',\\\n","    options = ['PR3732_T7_1730b_body00' + i for i in ['01.tif',\n"," '02.tif', '03.tif', '04.tif', '05.tif', '06.tif', '07.tif', '08.tif',\n"," '09.tif', '10.tif', '11.tif', '12.tif', '13.tif', '14.tif', '15.tif',\n"," '16.tif', '17.tif', '18.tif', '19.tif', '20.tif', '21.tif', '22.tif',\n"," '23.tif', '24.tif', '25.tif', '26.tif', '27.tif', '28.tif', '29.tif',\n"," '30.tif', '31.tif', '32.tif', '33.tif', '34.tif', '35.tif', '36.tif',\n"," '37.tif', '38.tif', '39.tif', '40.tif', '41.tif', '42.tif', '43.tif',\n"," '44.tif', '45.tif', '46.tif', '47.tif', '48.tif', '49.tif', '50.tif',\n"," '51.tif', '52.tif', '53.tif', '54.tif', '55.tif', '56.tif', '57.tif',\n"," '58.tif', '59.tif', '60.tif', '61.tif', '62.tif', '63.tif', '64.tif',\n"," '65.tif', '66.tif', '67.tif', '68.tif', '69.tif', '70.tif', '71.tif',\n"," '72.tif', '73.tif', '74.tif', '75.tif', '76.tif', '77.tif', '78.tif',\n"," '79.tif', '80.tif', '81.tif', '82.tif', '83.tif', '84.tif', '85.tif', '86.tif']],\\\n","    value = 'PR3732_T7_1730b_body0001.tif',\n","    style={'description_width': 'initial'})\n","display(image_select)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Kz2HNNh27v96"},"source":["#Code cell #5\n","source_image = image_source_directory + image_select.value"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WMCm0OtY8Cr6"},"source":["## 2 - Try Adaptive Thresholding\n","If you get good results with adaptive thresholding in this step, you can proceed to number 4 (Deskew or Save?)."]},{"cell_type":"code","metadata":{"id":"DxiIuAIT8HRA"},"source":["#Code cell #6\n","cv2color_image = cv2.imread(source_image, cv2.IMREAD_COLOR)\n","cv2gray_image = cv2.cvtColor(cv2color_image, cv2.COLOR_BGR2GRAY)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"14nCr0eq8Yyq"},"source":["#@title Set values for Gaussian blur {display-mode: \"form\"}\n","#@markdown Try adjusting the value that will be used for blurring in the next cell.\n","\n","#@markdown (You only need to run this cell once—re-running it will simply reset it to the default value. After changing the value of the slider, try re-running the cell below this one.)\n","blur = widgets.IntSlider(min=1, max=31, step=2, value=5, description='Blur')\n","display(blur)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9aizkL2j8aUc"},"source":["#Code cell #7\n","cv2blurred_image = cv2.GaussianBlur(cv2gray_image, (blur.value, blur.value), 0)\n","cv2_imshow(cv2blurred_image)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"muN0RZqN8m0I"},"source":["#Code cell #8\n","cv2binary_adaptive_image = cv2.adaptiveThreshold(cv2blurred_image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 101, 30)\n","cv2_imshow(cv2binary_adaptive_image)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PgTOxaFS9Lgi"},"source":["## 3 - Try Manual Thresholding\n","If you're not liking the results you're getting with adaptive thresholding, you can try manual thresholding, instead. When you've gotten the image looking good to your mind, move on to number 4 (Deskew or Save?)."]},{"cell_type":"code","metadata":{"id":"4eWXOa9o5vuO"},"source":["#Code cell #9\n","pilcolor_image = Image.open(source_image)\n","pilgray_image = pilcolor_image.convert('L')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2XTXdTWt80Pu"},"source":["#@title Set a threshold value {display-mode: \"form\"}\n"," #@markdown Run this cell, then use the slider that will appear to adjust the threshold point for our image in the cell below. \n"," \n"," #@markdown You only need to run this cell once (re-running it will just set things back to the default value). Try adjusting the slider and then re-running the *next* cell a few times to see the difference that different threshold values make.\n","thresh_value_slider = widgets.IntSlider(\n","    min=0,\n","    max=255,\n","    step=1,\n","    description='Threshold:',\n","    value=150\n",")\n","display(thresh_value_slider)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"D1BG2Uxa9g6E"},"source":["#Code cell #10\n","thresh = thresh_value_slider.value\n","fn = lambda x : 255 if x > thresh else 0\n","pilbinary_image = pilgray_image.convert('L').point(fn, mode='1')\n","pilbinary_image"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MavbDTV25NvC"},"source":["## 4 - Deskew or Save?"]},{"cell_type":"code","metadata":{"id":"_nPgyuNT9m-E","cellView":"form"},"source":["#{display-mode: 'form'}\n","#@markdown (Run this cell to create some widgets for this step.)\n","\n","#@markdown Do we need to deskew? If so, which thresholding method produced the better result?\n","\n","#@markdown If you're ready to save the image, select \"No\" and choose which\n","#@markdown thresholded image to save, then skip to the \"Save\" section and \n","#@markdown and proceed to re-OCR.\n","\n","#@markdown If the image needs deskewing, select \"Yes\" and indicate which of\n","#@markdown the thresholded images should be used for deskewing.\n","proceed_to_deskew = widgets.Dropdown(\n","    description='Deskew?',\\\n","    options = ['Yes', 'No'],\\\n","    value = 'Yes',\n","    style = {'description_width': 'initial'}\n","    )\n","thresholded_image = widgets.Dropdown(\n","    description='Deskew Method',\\\n","    options = ['Adaptive Threshold', 'Manual Threshold'],\\\n","    value = 'Adaptive Threshold',\n","    style={'description_width': 'initial'}\n","    )\n","display(proceed_to_deskew)\n","display(thresholded_image)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bPf26omo7PLA"},"source":["### 4.a - Deskew"]},{"cell_type":"code","metadata":{"id":"6DVoWVMO-I-P"},"source":["#Code cell #11\n","if thresholded_image.value == 'Adaptive Threshold' :\n","  image_to_deskew = cv2binary_adaptive_image\n","else :\n","  pass_to_cv2 = np.array(pilbinary_image) \n","  image_to_deskew = pass_to_cv2.astype(np.uint8) * 255\n","thresh = cv2.threshold(image_to_deskew, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JzRusw2Y-2_g"},"source":["#@title Set dilation variables { display-mode: \"form\" }\n","#@markdown (Run this cell to create a slider for setting the dilation amount.)\n","kernel_width = widgets.IntSlider(description = 'Kernel width', \\\n","                                               min=10, max=50, step=5, value=30)\n","kernel_height = widgets.IntSlider(description='Kernel height', \\\n","                                                 min=1, max=10, step=1, value=5)\n","num_iterations = widgets.IntSlider(description='Iterations', min=1, \\\n","                      max=10, step=1, value=5)\n","display(kernel_width) \n","display(kernel_height)\n","display(num_iterations)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HE_umtJj-_kO"},"source":["#Code cell #12\n","kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_width.value, kernel_height.value))\n","#We dilate the pixels using the shape defined by kernel, and perform the operation\n","#five times. You could try increasing or decreasing the number of iterations to\n","#see how the output changes.\n","dilate = cv2.dilate(thresh, kernel, iterations=num_iterations.value)\n","cv2_imshow(dilate)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vTXJ0eRn_LLm"},"source":["#Code cell #13\n","contours, hierarchy = cv2.findContours(dilate, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","sorted_contours = sorted(contours, key = cv2.contourArea, reverse = True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EppamiuyAv74"},"source":["#Code cell #14\n","def draw_min_area_rect(cv2minimumarearectangle, base_image) :\n","  draw_min_area_rect = cv2.cvtColor(base_image, cv2.COLOR_BayerGR2RGB)\n","  if isinstance(cv2minimumarearectangle, list) == True :\n","    print(len(cv2minimumarearectangle))\n","    for rect in cv2minimumarearectangle :\n","      min_area_box = cv2.boxPoints(rect)\n","      min_area_box = np.int0(min_area_box)\n","      draw_min_area_rect = cv2.line(draw_min_area_rect, (min_area_box[0][0], min_area_box[0][1]), \\\n","                                    (min_area_box[1][0], min_area_box[1][1]), (0, 30, 255), 3)\n","      draw_min_area_rect = cv2.line(draw_min_area_rect, (min_area_box[1][0], min_area_box[1][1]), \\\n","                                    (min_area_box[2][0], min_area_box[2][1]), (0, 30, 255), 3)\n","      draw_min_area_rect = cv2.line(draw_min_area_rect, (min_area_box[2][0], min_area_box[2][1]), \\\n","                                    (min_area_box[3][0], min_area_box[3][1]), (0, 30, 255), 3)\n","      draw_min_area_rect = cv2.line(draw_min_area_rect, (min_area_box[3][0], min_area_box[3][1]), \\\n","                                    (min_area_box[0][0], min_area_box[0][1]), (0, 30, 255), 3)\n","      cv2.putText(draw_min_area_rect, str(rect[-1]), \n","                  (int(rect[0][0]) -100, int(rect[0][1])), cv2.FONT_HERSHEY_SIMPLEX, \n","                  1, (0, 30, 255, 255), 3)\n","  else :\n","    min_area_box = cv2.boxPoints(cv2minimumarearectangle)\n","    min_area_box = np.int0(min_area_box)\n","    draw_min_area_rect = cv2.line(draw_min_area_rect, (min_area_box[0][0], min_area_box[0][1]), \\\n","                                  (min_area_box[1][0], min_area_box[1][1]), (0, 30, 255), 3)\n","    draw_min_area_rect = cv2.line(draw_min_area_rect, (min_area_box[1][0], min_area_box[1][1]), \\\n","                                  (min_area_box[2][0], min_area_box[2][1]), (0, 30, 255), 3)\n","    draw_min_area_rect = cv2.line(draw_min_area_rect, (min_area_box[2][0], min_area_box[2][1]), \\\n","                                  (min_area_box[3][0], min_area_box[3][1]), (0, 30, 255), 3)\n","    draw_min_area_rect = cv2.line(draw_min_area_rect, (min_area_box[3][0], min_area_box[3][1]), \\\n","                                  (min_area_box[0][0], min_area_box[0][1]), (0, 30, 255), 3)\n","    cv2.putText(draw_min_area_rect, str(cv2minimumarearectangle[-1]), \n","                (int(cv2minimumarearectangle[0][0]) -100, int(cv2minimumarearectangle[0][1])), \n","                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 30, 255, 255), 3)\n","\n","  return draw_min_area_rect"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B1xu0CamBFDw"},"source":["#@title Angle Calculation Method{display-mode: 'form'}\n","#@markdown (Run this cell to create a widget for use in this step.)\n","\n","#@markdown Do you want to use all minAreaRect angles for deskewing, or\n","#@markdown just the angles from a subset of the largest contours? \n","angle_method = widgets.Dropdown(\n","    description='Select method',\\\n","    options = ['All Rects', 'Selected'],\\\n","    value = 'All Rects',\n","    style={'description_width': 'initial'})\n","num_rects = widgets.IntSlider(description='Top rects', min=1, \\\n","                      max=5, step=1, value=1)\n","\n","display(angle_method)\n","display(num_rects)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LOR59uifB0O8"},"source":["#Code cell #15\n","rects = []\n","if angle_method.value == 'All Rects' :\n","  for contour in contours :\n","    minAreaRect = cv2.minAreaRect(contour)\n","    if minAreaRect[1][1] > 60 : \n","      if minAreaRect[-1] not in [-0.0, 0.0, -90.0] :\n","        rects.append(minAreaRect)\n","else :\n","  for contour in sorted_contours[0:num_rects.value] :\n","    minAreaRect = cv2.minAreaRect(contour)\n","    rects.append(minAreaRect)\n","\n","draw_all_rects = draw_min_area_rect(rects, dilate)\n","cv2_imshow(draw_all_rects)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"I4-f4xKrDJ2T"},"source":["#Code cell #16\n","angle_corrections = []\n","for rect in rects :\n","  if rect[-1] < -45 :\n","    angle_corrections.append((90 - (-1.0 * rect[-1]), -1))\n","  else :\n","    angle_corrections.append((90 - (90 + rect[-1]), 1))\n","average_angle = np.mean([angle_tuple[0] for angle_tuple in angle_corrections])\n","\n","plus_or_minus = sum(angle_tuple[1] for angle_tuple in angle_corrections)\n","if plus_or_minus > 0 :\n","  average_angle = -1.0 * average_angle"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GNkYS8kiDaH9"},"source":["#Code cell #17\n","average_angle_deskew = image_to_deskew.copy()\n","(h, w) = average_angle_deskew.shape[:2]\n","center = (w // 2, h // 2)\n","# M = cv2.getRotationMatrix2D(center, angle, 1.0)\n","M = cv2.getRotationMatrix2D(center, average_angle, 1.0)\n","deskewed_average_angle = cv2.warpAffine(average_angle_deskew, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n","cv2_imshow(deskewed_average_angle)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QxAa78dZ6J5v"},"source":["### 4.b - Save\n","Save the reprocessed image before re-OCR'ing."]},{"cell_type":"code","metadata":{"id":"xwwFyBUfEBbU"},"source":["#Code cell #18\n","import os\n","output_directory = '/content/page_iamges/penn_pr3732_t7_1730/bw/'\n","if os.path.exists(output_directory) is not True :\n","  os.makedirs(output_directory)\n","outname = image_select.value.rstrip('.tif') + '-bw.tif'\n","with open(image_source_directory + 'bw/' + outname, 'wb') as new_image :\n","  if proceed_to_deskew.value == 'Yes' :\n","    final_image = Image.fromarray(deskewed_average_angle)\n","\n","  else :\n","    if thresholded_image.value == 'Adaptive Threshold' :\n","      final_image = Image.fromarray(cv2binary_adaptive_image)\n","\n","    if thresholded_image.value == 'Manual Threshold' :\n","      pass_to_cv2 = np.array(pilbinary_image) \n","      intermediate_image = pass_to_cv2.astype(np.uint8) * 255\n","      final_image = Image.fromarray(intermediate_image)\n","      \n","  print('Saving ' + image_source_directory + outname)\n","  final_image.save(new_image)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wwI7f8BFggxF"},"source":["## Move output files back to Google Drive"]},{"cell_type":"code","metadata":{"id":"ToNv6vSzglU7"},"source":["#Code cell #19\n","%cd content/page_images/\n","!zip -r penn_pr3732_t7_1730b.zip penn_pr3732_t7_1730b/\n","!mv penn_pr3732_t7_1730b.zip /gdrive/MyDrive/rbs_digital_approaches_2021/output/penn_pr3732_t7_1730b.zip\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hfL44985fqsc"},"source":["## Clear Colaboratory environment"]},{"cell_type":"code","metadata":{"id":"AYbptmujftlS"},"source":["#Code cell #20\n","%cd /content/\n","!rm -r ./*"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8I-o2DSeL3TB"},"source":["## Moving on to preliminary OCR to get hOCR output\n","The next notebook will have you moving files back into the Colaboratory environment to perform preliminary OCR to get hOCR output and then slice up your page images into line level images. That will be the last step for now!"]}]}