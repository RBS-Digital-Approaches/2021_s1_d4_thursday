{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2021_s1_d4_m2c_page_deskewing.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyPbf+M0uPT0+PU7tTiy/hzk"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"wh2j0fLvij2q"},"source":["#Deskewing pages using OpenCV and Python#\n","When we think about training OCR, we often focus on refining the software's ability to recognize particular characters, or providing domain-specific vocabulary lists to improve the software's repertoire for recognizing words. But one of the most important things we can do to improve text recognition is to optimize the quality of the images we're asking the software to process in the first place.\n","\n","The code in this notebook is drawn from a blog post by Leo Ertuna at [Becoming Human](https://becominghuman.ai/how-to-automatically-deskew-straighten-a-text-image-using-opencv-a0c30aed83df). Ertuna has written this deskewing routine as a set of defined functions that would be invoked by invoking a `deskew`  function and passing it the name of an image [i.e., `deskew(image_name)`]. \n","\n","This notebook breaks Ertuna's code up into interactive steps to show what's happening along the way, then offers a revision of one of Ertuna's techniques that may offer a slightly improved result."]},{"cell_type":"markdown","metadata":{"id":"EeYTN8gDMyb9"},"source":["### A note before we start: this may not be the only problem to solve\n","The code in this notebook assumes that the problem with the page image is that it's skewed and needs to straightened—this treats the page as a two-dimensional plane. \n","\n","That works pretty well if the images are of reasonably flat pages of the kind that we can often get from the sort of imaging labs that many libraries have. But books don't necessarily lay flat, and, depending on the condition of the binding, it may not always possible to flatten the pages for imaging. So the lines of text in some images will appear not just skewed, but actually curved, due to the curvature of the pages. And pages in a book can curl in a number of ways all at once (recall, for instance how much more and how differently the pages in the middle of a thick book curl compared to pages at the beginning or end.)\n","\n","It's possible to reduce or eliminate the appearance of curvature in the lines of a page image incorporating some of techniques we'll see in this deskewing routine (but adding some others). That's a more complicated problem that we won't take on, but there's a great [blog post by Mark Zucker](https://mzucker.github.io/2016/08/15/page-dewarping.html) that walks through a solution. The blog post offers visualizations of what's happening at each step, so it's an instructive read even if you're not examining the details of the code.\n","\n","(Zucker's [full code is on GitHub](https://github.com/mzucker/page_dewarp), but it's written for Python 2, rather than Python 3. Robert Sachunsky has a [fork of Zucker's code](https://github.com/bertsky/page_dewarp) for Python 3.) "]},{"cell_type":"markdown","metadata":{"id":"xhhbM2leRoE2"},"source":["## Connect to Google Drive, copy files, and install packages"]},{"cell_type":"code","metadata":{"id":"vr2ZLKaBb8Kc"},"source":["#Get access to Google Drive\n","from google.colab import drive\n","drive.mount('/gdrive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kM_B4qhhc4bp"},"source":["%cp -r /gdrive/MyDrive/rbs_digital_approaches_2021/data_class/page_images/penn_pr3732_t7_1730b.zip /content/penn_pr3732_t7_1730b.zip\n","%cd /content/\n","!unzip penn_pr3732_t7_1730b.zip"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h5kdzNrKcbUL"},"source":["#Install IPyWidgets to provide widgets for experimenting with some variables later\n","import ipywidgets as widgets\n","from ipywidgets import interact\n","\n","#Import necessary Python packages for use in our code. \n","\n","#Note that opencv-python is installed by default in Google Colaboratory. If you \n","#were working in a different environment, you'd need to be sure it was installed\n","#using pip\n","\n","#(The second import is specific to Google Colaboratory and provides a workaround\n","#to get OpenCV's imshow command to work properly in a Colab notebook.\n","import cv2\n","from google.colab.patches import cv2_imshow\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aO7EsJLZR5K6"},"source":["## Opening the image\n","Run the next cell to get a drop-down list of different images for processing, all with varying levels of skewing. (You only need to run that cell once. Thereafter, you can change the image you're working with by choosing a different image from the select menu.)"]},{"cell_type":"code","metadata":{"id":"TAxKrLvwC6zw"},"source":["image_select = widgets.Dropdown(\n","    description='Choose image',\\\n","    options = ['PR3732_T7_1730b_body00' + i for i in ['04.tif', '11.tif', '13.tif', '21.tif', '36.tif', '63.tif', '78.tif', '82.tif']],\\\n","    value = 'PR3732_T7_1730b_body0004.tif',\n","    style={'description_width': 'initial'})\n","display(image_select)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rWyifXGpdPDR"},"source":["#Identify the skewed image and have OpenCV read it. (This can take a little \n","#while, so give it time to complete.)\n","\n","source_directory = '/content/penn_pr3732_t7_1730b/'\n","skewed_image = source_directory + image_select.value\n","im = cv2.imread(skewed_image, cv2.IMREAD_COLOR)\n","#Let's see what the image looks like: an excellent image, but a little skewed.\n","cv2_imshow(im)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"S22E8xx2n42d"},"source":["##Manipulating the image##\n","Tesseract might well be able to handle an image like this, but recognition of text lines will be better if we can straighten it. Ertuna's script offers a nice example of a workflow for figuring out exactly *how* skewed the image is, then using that measurement to straighten the image. As we proceed, you'll see some of the ways that images that are good for *us* are not as useful for the computer, and vice versa."]},{"cell_type":"code","metadata":{"id":"JLPMgkleaPEW"},"source":["#Make a copy of the image\n","newImage = im.copy()\n","#Convery to grayscale\n","gray = cv2.cvtColor(newImage, cv2.COLOR_BGR2GRAY)\n","#Apply a Gaussian blur to reduce the effect of any noise in the image\n","blur = cv2.GaussianBlur(gray, (9, 9), 0)\n","#Convert the image to inverted black and white (i.e., white text on a \n","#black background). Note that Ertuna's script uses Otsu's method for \n","#thresholding to black and white.\n","thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n","cv2_imshow(thresh)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xplCmGRlS4J3"},"source":["### Set some variables\n","Run the next cell to create a few sliders that will allow you to adjust the variables used in the next steps. (You only need to run that cell once. Thereafter, changing the sliders will change the values of the variables used in the subsequent cells.)"]},{"cell_type":"code","metadata":{"id":"WNEI3nnFnG_7"},"source":["kernel_width = widgets.IntSlider(description = 'Kernel width', \\\n","                                               min=10, max=50, step=5, value=30)\n","kernel_height = widgets.IntSlider(description='Kernel height', \\\n","                                                 min=1, max=10, step=1, value=5)\n","num_iterations = widgets.IntSlider(description='Iterations', min=1, \\\n","                      max=10, step=1, value=5)\n","display(kernel_width) \n","display(kernel_height)\n","display(num_iterations)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"u7avDI3XfOOJ"},"source":["###Now things start to get strange...###\n","Ertuna implements a common approach that may seem counterintuitive at first: we're going to `dilate` the white pixels of the text until they run together to form solid blocks of white. \n","The next cell creates a set of sliders so you can play with the values that determine the size of the `kernel` used to dilate those pixels and the number of iterations for dilation (the defaults follow Ertuna's script). \n","NOTE: After you've run the next cell to create the sliders, don't run it again—that will just reset the values to their defaults. Instead, make any adjustments to the sliders and then run the cell *below*."]},{"cell_type":"code","metadata":{"id":"ga-SDNWCakMh"},"source":["#The kernel variable defines a shape to use for dilating the pixels: in this \n","#case, a rectangle of 30 pixels wide and 5 pixels high. These proportions ensure\n","# that the text will run together while more or less maintaining the vertical \n","#dimensions of the text lines. You could experiment with changing the x and y\n","#dimensions that are passed to cv2.MORPH_RECT to see how the output changes.\n","kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_width.value, kernel_height.value))\n","#We dilate the pixels using the shape defined by kernel, and perform the operation\n","#five times. You could try increasing or decreasing the number of iterations to\n","#see how the output changes.\n","dilate = cv2.dilate(thresh, kernel, iterations=num_iterations.value)\n","cv2_imshow(dilate)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"43N1xuI7g7Op"},"source":["This cell finds the boundaries of the dilated white blocks that used to be our text lines and determines their contours. \n","I've made one adjustment to Ertuna's script here in using the `RETR_EXTERNAL` method rather than the `RETR_LIST` method that Ertuna used. Ertuna's method retrieves *all* contours that are detected, where `RETR_EXTERNAL` ignores contours that are found *within other contours*. Though I can't say I've tested it entirely systematically, this approach seems to do a better job of detecting text blocks in this eighteenth-century text, where what may be wandering in the baseline of the set type creates some gaps that end up being detected as contours."]},{"cell_type":"code","metadata":{"id":"dEyqVb6ha5VB"},"source":["#Determine contours [more info here]\n","contours, hierarchy = cv2.findContours(dilate, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","\n","#These next steps are not really part of the deskewing sequence. I've included \n","#them simply so we can see what's happening. We first create a color version\n","#of our black-and-white image, then draw a bright green line connecting the\n","#contour points so we can see the outlines of the detected shapes\n","show_contours = cv2.cvtColor(dilate, cv2.COLOR_BayerGR2RGB)\n","draw_contours = cv2.drawContours(show_contours, contours, -1, (115,255,105), 3)\n","cv2_imshow(draw_contours)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Uy5WJ4ROiavU"},"source":["###Finding the rectangle that fits this contour###\n","Ertuna's script acts on only the largest of the detected areas on the not-unreasonable premise that the skew angle of the largest text block will be a good proxy for the skew angle of the entire page of text. (He notes, though, that other approaches are possible. One might find that the angle of a different block yielded better results, or the average of multiple blocks.)\n","\n","Having selected the largest contour, the code in the next cell then determines the smallest possible rectangle that could contain the entire contour using `minAreaRect`: basically, we're drawing a straight-sided box around the irregular contour of the text block.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"mkkz_e_Ckh5V"},"source":["(The code in the following cell is, again, not really part of the deskewing procedure, but I have added it to show what's happening.)\n","\n","Actually, what `minAreaRect` produces is not exactly a rectangle, but rather some *instructions* for making a rectangle. We get:\n","- the x, y coordinates of the center point;\n","- the width and height of the rectangle; and\n","- the angle of the rectangle (for more on how `minAreaRect` treats this angle, see [this post at *The AI Learner*](https://theailearner.com/tag/cv2-minarearect/).)\n","\n","To actually draw the rectangle described by `minAreaRect`, the following cell uses OpenCV's `boxPoints` to get the corner points, then draws a series of lines to connect those corners."]},{"cell_type":"code","metadata":{"id":"YlqhgCKAdjz3"},"source":["#This sorts the set of contour points in reverse order: the contours of the \n","#largest area will be first in this sorted, which will come in handy in the next\n","#cell.\n","sorted_contours = sorted(contours, key = cv2.contourArea, reverse = True)\n","#Select the largest detected contour\n","largest_contour = sorted_contours[0]\n","#Determine the minimum-area rectangle that would contain that contour\n","largest_min_area_rect = cv2.minAreaRect(largest_contour)\n","print(largest_min_area_rect)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"o1tU-RbJxJqw"},"source":["def draw_min_area_rect(cv2minimumarearectangle, base_image) :\n","  draw_min_area_rect = cv2.cvtColor(base_image, cv2.COLOR_BayerGR2RGB)\n","  if isinstance(cv2minimumarearectangle, list) == True :\n","    print(len(cv2minimumarearectangle))\n","    for rect in cv2minimumarearectangle :\n","      min_area_box = cv2.boxPoints(rect)\n","      min_area_box = np.int0(min_area_box)\n","      draw_min_area_rect = cv2.line(draw_min_area_rect, (min_area_box[0][0], min_area_box[0][1]), \\\n","                                    (min_area_box[1][0], min_area_box[1][1]), (0, 30, 255), 3)\n","      draw_min_area_rect = cv2.line(draw_min_area_rect, (min_area_box[1][0], min_area_box[1][1]), \\\n","                                    (min_area_box[2][0], min_area_box[2][1]), (0, 30, 255), 3)\n","      draw_min_area_rect = cv2.line(draw_min_area_rect, (min_area_box[2][0], min_area_box[2][1]), \\\n","                                    (min_area_box[3][0], min_area_box[3][1]), (0, 30, 255), 3)\n","      draw_min_area_rect = cv2.line(draw_min_area_rect, (min_area_box[3][0], min_area_box[3][1]), \\\n","                                    (min_area_box[0][0], min_area_box[0][1]), (0, 30, 255), 3)\n","      cv2.putText(draw_min_area_rect, str(rect[-1]), \n","                  (int(rect[0][0]) -100, int(rect[0][1])), cv2.FONT_HERSHEY_SIMPLEX, \n","                  1, (0, 30, 255, 255), 3)\n","  else :\n","    min_area_box = cv2.boxPoints(cv2minimumarearectangle)\n","    min_area_box = np.int0(min_area_box)\n","    draw_min_area_rect = cv2.line(draw_min_area_rect, (min_area_box[0][0], min_area_box[0][1]), \\\n","                                  (min_area_box[1][0], min_area_box[1][1]), (0, 30, 255), 3)\n","    draw_min_area_rect = cv2.line(draw_min_area_rect, (min_area_box[1][0], min_area_box[1][1]), \\\n","                                  (min_area_box[2][0], min_area_box[2][1]), (0, 30, 255), 3)\n","    draw_min_area_rect = cv2.line(draw_min_area_rect, (min_area_box[2][0], min_area_box[2][1]), \\\n","                                  (min_area_box[3][0], min_area_box[3][1]), (0, 30, 255), 3)\n","    draw_min_area_rect = cv2.line(draw_min_area_rect, (min_area_box[3][0], min_area_box[3][1]), \\\n","                                  (min_area_box[0][0], min_area_box[0][1]), (0, 30, 255), 3)\n","    cv2.putText(draw_min_area_rect, str(cv2minimumarearectangle[-1]), \n","                (int(cv2minimumarearectangle[0][0]) -100, int(cv2minimumarearectangle[0][1])), \n","                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 30, 255, 255), 3)\n","\n","  return draw_min_area_rect"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5On3YoXHv5nq"},"source":["largest_min_area = draw_min_area_rect(largest_min_area_rect, dilate)\n","cv2_imshow(largest_min_area)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BcaNsCwAoGjD"},"source":["###Back to the actual deskewing routine###\n","Getting the angle of the rectangle's skew is actually easier than drawing the rectangle: we just need the last number produced by `minAreaRect`, but because of the way `minAreaRect` measures the angle, we do need to have a bit of math to make sure the value comes out usable."]},{"cell_type":"code","metadata":{"id":"xefaAsQKwNCs"},"source":["# Determine the angle. Convert it to the value that was originally used to obtain skewed image\n","largest_rect_angle = largest_min_area_rect[-1]\n","if largest_rect_angle < -45:\n","    largest_rect_angle = 90 + largest_rect_angle\n","print(largest_rect_angle)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Y7PMczhaqF9b"},"source":["###Let's see the deskewed image.###\n","The code in the next cell takes a few steps to rotate our image \n","1. First, we make a copy of our original image\n","2. Next, we determine the size of the image by getting its height and width (the first two items returned by `shape`)\n","3. Then, we determine the center of the image by dividing its height and width by two.\n","4. Next, we construct the rotation we want to happen: rotating the image around its center point by the `angle` we determined in the previous cell, //and keeping the scale of the resulting image the same//??\n","5. [Need to undertand this part better to explain]\n","\n","Note how we're using information that we calculated by using what is to us a very strange-looking image, and applying it to our original color image."]},{"cell_type":"code","metadata":{"id":"9_6puKgfwm6j"},"source":["largest_rect_deskew = im.copy()\n","(h, w) = largest_rect_deskew.shape[:2]\n","center = (w // 2, h // 2)\n","# M = cv2.getRotationMatrix2D(center, angle, 1.0)\n","M = cv2.getRotationMatrix2D(center, largest_rect_angle, 1.0)\n","deskewed_largest_rect = cv2.warpAffine(largest_rect_deskew, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n","cv2_imshow(deskewed_largest_rect)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pZBWiVxCA4bw"},"source":["## A modification of Ertuna's approach for early print?###\n","Ertuna's approach uses the angle of the largest `minAreaRect` for deskewing. This seems like it would be a pretty sound approach if we were dealing with deskewing, say, a page printed from a laser printer that had subsequently been scanned with the paper skewed slightly on scanner bed. \n","\n","While this approach seemed to work well for images from the Penn *Sophonisba* that were significantly skewed, however, it actually seemed to make things slightly *worse* for some pages that were only minimally skewed. I'm not entirely sure what to make of this yet, but my hunch is that this result may arise from the character of pages produced on a printing press. Perhaps if the chase wasn't locked up tightly, different lines on the same page could deviate from horizontal by *different* amounts?\n","\n","Rather than relying solely on the largest text block, the code below sets a couple of threshold to detect as many text blocks as possible (while rejecting regions that seem like they're probably noise), then figures out an average angle for deskewing the entire page.\n"]},{"cell_type":"code","metadata":{"id":"dA0y_NPeI6WF"},"source":["#Going to try averaging angles of multiple minAreaRects...\n","rects = []\n","for contour in contours :\n","  minAreaRect = cv2.minAreaRect(contour)\n","  #minAreaRects with a height of less than 60 pixels seemed almost always to be\n","  #artifacts of noise, rather than text blocks we'd actually be interested in.\n","  if minAreaRect[1][1] > 60 : \n","    #Let's ignore any text block that appears to be perfectly horizontal--or \n","    #rotated 90 degrees. On a normal page, any text block in the latter category \n","    #almost always seems to be noise (like a shadow in the gutter or at the \n","    #margin).\n","    if minAreaRect[-1] not in [-0.0, 0.0, -90.0] :\n","      rects.append(minAreaRect)\n","draw_all_rects = draw_min_area_rect(rects, dilate)\n","cv2_imshow(draw_all_rects)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OD8YryJwid8B"},"source":["#We're only interested in the angles from the minAreaRects, but we also \n","#need to keep track of which direction the block is skewed. This creates\n","#an empty list that will hold a series of tuples: the first element will\n","#be the angle, and the second will be either 1 or -1)\n","angle_corrections = []\n","for rect in rects :\n","  if rect[-1] < -45 :\n","    #For angles of less than -45 degrees, construct a tuple with\n","    #the deviation from 90 degrees as the first term\n","    #(e.g., 90 - (-1 * 87.6834) = 90 - 87.6834 = 2.3166)\n","    #as the first term and -1 as the second\n","    angle_corrections.append((90 - (-1.0 * rect[-1]), -1))\n","  else :\n","    #For angles of greater than -45, construct a tuple with\n","    #the deviation from 90 degrees as the first term\n","    #(e.g. 90 - 90 + -1.4596 = 90 - 88.5404 = 1.4596)\n","    #and 1 as the second term\n","    angle_corrections.append((90 - (90 + rect[-1]), 1))\n","#Determine the mean of the first terms of all of the tuples\n","#in our list of angle_corrections\n","average_angle = np.mean([angle_tuple[0] for angle_tuple in angle_corrections])\n","\n","#Determine whether the deskew angle should be treated as positive\n","#or negative by taking the sum of the second terms of all \n","#of the tuples (e.g., -1 + -1 + -1 + 1 + -1 = -3)\n","plus_or_minus = sum(angle_tuple[1] for angle_tuple in angle_corrections)\n","#If that sum ends up as a positive number, the deskewing angle\n","#needs to be a negative number\n","if plus_or_minus > 0 :\n","  average_angle = -1.0 * average_angle\n","print(plus_or_minus)\n","print(average_angle)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bnbxB5-nblue"},"source":["average_angle_deskew = im.copy()\n","(h, w) = average_angle_deskew.shape[:2]\n","center = (w // 2, h // 2)\n","# M = cv2.getRotationMatrix2D(center, angle, 1.0)\n","M = cv2.getRotationMatrix2D(center, average_angle, 1.0)\n","deskewed_average_angle = cv2.warpAffine(average_angle_deskew, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n","cv2_imshow(deskewed_average_angle)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yBjM3jxP4m4V"},"source":["### Comparing the output\n","This image overlays the results of the two deskewing approaches in the notebook: the image in red was deskewed using the largest rectangle method, while the one in blue was desweked using the averages of the multiple rectangles. In many cases, the results are *ver* similar, though I think that in some cases the second approach may produce a somewhat better result."]},{"cell_type":"code","metadata":{"id":"qqUGRnseEA1h"},"source":["def tint_image(cv2image, color) :\n","  if color == 'red' :\n","    color_value = [0,0,255]\n","  if color == 'blue' :\n","    color_value = [255, 0, 0]\n","  if color == 'green' :\n","    color_value = [0,255,0]\n","  tint_gray = cv2.cvtColor(cv2image, cv2.COLOR_BGR2GRAY)\n","  # tint_blur = cv2.GaussianBlur(tint_gray, (9, 9), 0)\n","  tint_thresh = cv2.threshold(tint_gray, 0, 255, cv2.THRESH_OTSU)[1]\n","  tint = cv2.cvtColor(tint_thresh, cv2.COLOR_BAYER_GR2BGR)\n","  tint[np.where((tint==[0,0,0]).all(axis=2))] = color_value\n","  return tint\n","\n","tint_red = tint_image(deskewed_largest_rect, 'red')\n","tint_blue = tint_image(deskewed_average_angle, 'blue')\n","output = cv2.addWeighted(tint_blue,0.6, tint_red, 0.4, 0)\n","cv2_imshow(output)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"e-W2pJFZd8qb"},"source":["## Clear Google Colab environment"]},{"cell_type":"code","metadata":{"id":"5-T0W4VLeAS2"},"source":["%cd /content/\n","!rm -r ./*"],"execution_count":null,"outputs":[]}]}